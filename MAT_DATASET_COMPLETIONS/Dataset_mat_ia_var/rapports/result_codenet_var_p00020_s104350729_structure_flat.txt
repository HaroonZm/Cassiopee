================================================================================
ANALYSE DES PRÉDICTIONS DE TOKENS
================================================================================

SCRIPT ORIGINAL:
--------------------------------------------------------------------------------
s = raw_input()
s = s.upper()
print(s)
--------------------------------------------------------------------------------

INFORMATION SUR LA TOKENISATION:
--------------------------------------------------------------------------------
Tokenisation utilisée: tiktoken pour le modèle gpt-4o-mini
Il s'agit de la tokenisation officielle utilisée par les modèles OpenAI.
--------------------------------------------------------------------------------

TOKENS IDENTIFIÉS:
--------------------------------------------------------------------------------
Token 0: 's' (ID: 82)
Token 1: ' =' (ID: 314)
Token 2: ' raw' (ID: 11428)
Token 3: '_input' (ID: 12507)
Token 4: '()\n' (ID: 1234)
Token 5: 's' (ID: 82)
Token 6: ' =' (ID: 314)
Token 7: ' s' (ID: 265)
Token 8: '.upper' (ID: 75082)
Token 9: '()\n' (ID: 1234)
Token 10: 'print' (ID: 1598)
Token 11: '(s' (ID: 1858)
Token 12: ')' (ID: 8)
--------------------------------------------------------------------------------

INFORMATIONS SUR LA MATRICE 2D DE LOG PROBABILITÉS:
--------------------------------------------------------------------------------
Dimensions de la matrice: 3 lignes x 5 tokens max
Nombre de tokens par ligne: [5, 5, 3]
Convention de valeurs:
  - Log probabilité normale: Valeur réelle (typiquement entre -1 et -20)
  - Anomalie (token hors top-10): -50
  - Padding (positions vides): 100

Matrice 2D (format texte simplifiée):
[-10.00, -10.00, -10.00, -1.02, -2.85, ]
[-3.21, -0.18, -0.45, -5.19, -0.44, ]
[-2.02, -0.93, -0.69, PAD, PAD, ]

Note: La matrice a été sauvegardée au format numpy dans 'matrice_logprob.npy'
--------------------------------------------------------------------------------

ANALYSE TOKEN PAR TOKEN:
--------------------------------------------------------------------------------
Position 0: 's' (ID: 82) (token d'amorce)
--------------------------------------------------------------------------------

Position 1: ' =' (ID: 314) (token d'amorce)
--------------------------------------------------------------------------------

Position 2: ' raw' (ID: 11428) (token d'amorce)
--------------------------------------------------------------------------------

Position 3: '_input' (ID: 12507)
Prédiction principale: '_input' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '_input' (logprob: -1.0219) [Prédiction principale]
  2. '_data' (logprob: -2.1469)
  3. 'Data' (logprob: -3.2719)
  4. '[' (logprob: -3.8969)
  5. '_s' (logprob: -3.8969)
  6. 'Input' (logprob: -3.8969)
  7. 'data' (logprob: -4.0219)
  8. '.split' (logprob: -4.5219)
  9. '_' (logprob: -4.8969)
  10. '_text' (logprob: -4.8969)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 4: '()\n' (ID: 1234)
Prédiction principale: '("' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '("' (logprob: -0.5982) [Prédiction principale]
  2. '('' (logprob: -1.7232)
  3. '().' (logprob: -2.3482)
* 4. '()\n' (logprob: -2.8482)
  5. '.split' (logprob: -3.9732)
  6. '()' (logprob: -4.5982)
  7. '("\\' (logprob: -4.5982)
  8. '()\n\n' (logprob: -4.9732)
  9. '(' (logprob: -5.5982)
  10. '('\\' (logprob: -5.5982)

Le token attendu est à la position 4 dans les prédictions.

--------------------------------------------------------------------------------

Position 5: 's' (ID: 82)
Prédiction principale: '   ' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '   ' (logprob: -1.8324) [Prédiction principale]
  2. '       ' (logprob: -2.4574)
  3. 'print' (logprob: -2.5824)
  4. '#' (logprob: -2.9574)
  5. 'if' (logprob: -3.0824)
* 6. 's' (logprob: -3.2074)
  7. '    \n' (logprob: -3.2074)
  8. '           ' (logprob: -3.5824)
  9. 'while' (logprob: -3.8324)
  10. 'n' (logprob: -3.9574)

Le token attendu est à la position 6 dans les prédictions.

--------------------------------------------------------------------------------

Position 6: ' =' (ID: 314)
Prédiction principale: ' =' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. ' =' (logprob: -0.1766) [Prédiction principale]
  2. '_list' (logprob: -3.6766)
  3. '1' (logprob: -3.8016)
  4. '2' (logprob: -4.4266)
  5. ' +=' (logprob: -4.5516)
  6. '=s' (logprob: -4.6766)
  7. 'ums' (logprob: -4.8016)
  8. '=' (logprob: -4.9266)
  9. 'List' (logprob: -5.0516)
  10. 'list' (logprob: -5.4266)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 7: ' s' (ID: 265)
Prédiction principale: ' s' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. ' s' (logprob: -0.4517) [Prédiction principale]
  2. ' list' (logprob: -2.4517)
  3. ' int' (logprob: -2.9517)
  4. ' [' (logprob: -3.0767)
  5. ' re' (logprob: -3.3267)
  6. ' map' (logprob: -3.8267)
  7. ' raw' (logprob: -3.9517)
  8. ' ''.' (logprob: -4.2017)
  9. ' '' (logprob: -4.5767)
  10. ' str' (logprob: -4.5767)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 8: '.upper' (ID: 75082)
Prédiction principale: '.split' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '.split' (logprob: -0.4401) [Prédiction principale]
  2. '.strip' (logprob: -2.0651)
  3. '.lower' (logprob: -2.1901)
  4. '.replace' (logprob: -2.6901)
  5. '[' (logprob: -4.5651)
  6. '[::-' (logprob: -4.8151)
  7. ' +' (logprob: -5.1901)
* 8. '.upper' (logprob: -5.1901)
  9. '.rstrip' (logprob: -5.3151)
  10. '[:-' (logprob: -5.8151)

Le token attendu est à la position 8 dans les prédictions.

--------------------------------------------------------------------------------

Position 9: '()\n' (ID: 1234)
Prédiction principale: '()\n' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '()\n' (logprob: -0.4436) [Prédiction principale]
  2. '()\n\n' (logprob: -1.5686)
  3. '()' (logprob: -2.1936)
  4. '().' (logprob: -3.4436)
  5. '()\n\n\n' (logprob: -5.3186)
  6. '()[' (logprob: -7.6936)
  7. '();\n' (logprob: -8.3186)
  8. '();\n\n' (logprob: -8.9436)
  9. '();' (logprob: -9.0686)
  10. '()\r\n' (logprob: -9.3186)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 10: 'print' (ID: 1598)
Prédiction principale: 's' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. 's' (logprob: -1.7685) [Prédiction principale]
* 2. 'print' (logprob: -2.0185)
  3. 'if' (logprob: -2.5185)
  4. 'for' (logprob: -2.7685)
  5. 'n' (logprob: -3.0185)
  6. 'count' (logprob: -3.3935)
  7. '#' (logprob: -3.6435)
  8. 'v' (logprob: -3.8935)
  9. 'l' (logprob: -4.0185)
  10. 'result' (logprob: -4.0185)

Le token attendu est à la position 2 dans les prédictions.

--------------------------------------------------------------------------------

Position 11: '(s' (ID: 1858)
Prédiction principale: '(s' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '(s' (logprob: -0.9322) [Prédiction principale]
  2. ' s' (logprob: -1.0572)
  3. ' "' (logprob: -2.8072)
  4. '("' (logprob: -3.3072)
  5. ' '' (logprob: -3.4322)
  6. ' (' (logprob: -3.6822)
  7. '('' (logprob: -4.4322)
  8. ' len' (logprob: -4.6822)
  9. '(' (logprob: -5.3072)
  10. ' ("' (logprob: -5.4322)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 12: ')' (ID: 8)
Prédiction principale: ')' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. ')' (logprob: -0.6924) [Prédiction principale]
  2. ')\n' (logprob: -0.9424)
  3. ')\n\n' (logprob: -2.8174)
  4. '.count' (logprob: -4.4424)
  5. '[::-' (logprob: -4.6924)
  6. '[' (logprob: -4.9424)
  7. '.replace' (logprob: -5.3174)
  8. ',' (logprob: -5.9424)
  9. '[:' (logprob: -6.1924)
  10. ')\n\n\n' (logprob: -6.3174)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------


RÉSUMÉ:
--------------------------------------------------------------------------------
Total des tokens analysés: 10
Tokens correctement prédits (1ère position, stricte): 6
Tokens correctement prédits (1ère position, avec adaptation): 6
Tokens correctement prédits (top 10): 10
Précision stricte (1ère position): 60.00%
Précision adaptée (1ère position): 60.00%
Précision (top 10): 100.00%
================================================================================

================================================================================
ANALYSE DES PRÉDICTIONS DE TOKENS
================================================================================

SCRIPT ORIGINAL:
--------------------------------------------------------------------------------
s = input()
s = s.upper()
print(s)
--------------------------------------------------------------------------------

INFORMATION SUR LA TOKENISATION:
--------------------------------------------------------------------------------
Tokenisation utilisée: tiktoken pour le modèle gpt-4o-mini
Il s'agit de la tokenisation officielle utilisée par les modèles OpenAI.
--------------------------------------------------------------------------------

TOKENS IDENTIFIÉS:
--------------------------------------------------------------------------------
Token 0: 's' (ID: 82)
Token 1: ' =' (ID: 314)
Token 2: ' input' (ID: 3422)
Token 3: '()\n' (ID: 1234)
Token 4: 's' (ID: 82)
Token 5: ' =' (ID: 314)
Token 6: ' s' (ID: 265)
Token 7: '.upper' (ID: 75082)
Token 8: '()\n' (ID: 1234)
Token 9: 'print' (ID: 1598)
Token 10: '(s' (ID: 1858)
Token 11: ')' (ID: 8)
--------------------------------------------------------------------------------

INFORMATIONS SUR LA MATRICE 2D DE LOG PROBABILITÉS:
--------------------------------------------------------------------------------
Dimensions de la matrice: 3 lignes x 5 tokens max
Nombre de tokens par ligne: [4, 5, 3]
Convention de valeurs:
  - Log probabilité normale: Valeur réelle (typiquement entre -1 et -20)
  - Anomalie (token hors top-10): -50
  - Padding (positions vides): 100

Matrice 2D (format texte simplifiée):
[-10.00, -10.00, -10.00, -3.53, PAD, ]
[-2.68, -0.29, -0.46, -5.09, -0.78, ]
[-2.62, -0.17, -0.55, PAD, PAD, ]

Note: La matrice a été sauvegardée au format numpy dans 'matrice_logprob.npy'
--------------------------------------------------------------------------------

ANALYSE TOKEN PAR TOKEN:
--------------------------------------------------------------------------------
Position 0: 's' (ID: 82) (token d'amorce)
--------------------------------------------------------------------------------

Position 1: ' =' (ID: 314) (token d'amorce)
--------------------------------------------------------------------------------

Position 2: ' input' (ID: 3422) (token d'amorce)
--------------------------------------------------------------------------------

Position 3: '()\n' (ID: 1234)
Prédiction principale: '("' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '("' (logprob: -0.6542) [Prédiction principale]
  2. '().' (logprob: -1.6542)
  3. '('' (logprob: -3.2792)
* 4. '()\n' (logprob: -3.5292)
  5. '.split' (logprob: -3.5292)
  6. '_string' (logprob: -3.7792)
  7. 'String' (logprob: -4.6542)
  8. '_str' (logprob: -4.6542)
  9. '_list' (logprob: -4.7792)
  10. '_data' (logprob: -4.9042)

Le token attendu est à la position 4 dans les prédictions.

--------------------------------------------------------------------------------

Position 4: 's' (ID: 82)
Prédiction principale: 'print' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. 'print' (logprob: -2.3091) [Prédiction principale]
  2. 'n' (logprob: -2.6841)
* 3. 's' (logprob: -2.6841)
  4. '#' (logprob: -2.8091)
  5. 'if' (logprob: -3.5591)
  6. 'result' (logprob: -3.5591)
  7. 'for' (logprob: -3.6841)
  8. 't' (logprob: -3.9341)
  9. 'count' (logprob: -3.9341)
  10. 'a' (logprob: -4.0591)

Le token attendu est à la position 3 dans les prédictions.

--------------------------------------------------------------------------------

Position 5: ' =' (ID: 314)
Prédiction principale: ' =' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. ' =' (logprob: -0.2864) [Prédiction principale]
  2. '_list' (logprob: -2.7864)
  3. '1' (logprob: -3.0364)
  4. '2' (logprob: -3.6614)
  5. ' +=' (logprob: -4.2864)
  6. 'ums' (logprob: -4.5364)
  7. '_len' (logprob: -4.7864)
  8. '_' (logprob: -5.1614)
  9. 'List' (logprob: -5.2864)
  10. '_count' (logprob: -5.5364)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 6: ' s' (ID: 265)
Prédiction principale: ' s' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. ' s' (logprob: -0.4558) [Prédiction principale]
  2. ' list' (logprob: -1.8308)
  3. ' [' (logprob: -3.0808)
  4. ' re' (logprob: -3.4558)
  5. ' ''.' (logprob: -3.5808)
  6. ' int' (logprob: -3.7058)
  7. ' sorted' (logprob: -4.0808)
  8. ' '' (logprob: -4.7058)
  9. ' set' (logprob: -4.8308)
  10. ' "".' (logprob: -5.0808)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 7: '.upper' (ID: 75082)
Prédiction principale: '.split' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '.split' (logprob: -0.7170) [Prédiction principale]
  2. '.replace' (logprob: -1.7170)
  3. '.lower' (logprob: -1.9670)
  4. '.strip' (logprob: -2.2170)
  5. '[' (logprob: -3.8420)
  6. '[::-' (logprob: -3.8420)
  7. ' +' (logprob: -4.8420)
* 8. '.upper' (logprob: -5.0920)
  9. '[:-' (logprob: -5.2170)
  10. '.rstrip' (logprob: -5.2170)

Le token attendu est à la position 8 dans les prédictions.

--------------------------------------------------------------------------------

Position 8: '()\n' (ID: 1234)
Prédiction principale: '()\n' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '()\n' (logprob: -0.7847) [Prédiction principale]
  2. '()' (logprob: -1.2847)
  3. '()\n\n' (logprob: -1.4097)
  4. '().' (logprob: -3.9097)
  5. '()\n\n\n' (logprob: -6.4097)
  6. '()[' (logprob: -7.4097)
  7. '(' (logprob: -8.9097)
  8. '();' (logprob: -10.1597)
  9. '()\r\n' (logprob: -10.6597)
  10. '()\r\n\r\n' (logprob: -10.6597)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 9: 'print' (ID: 1598)
Prédiction principale: 's' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. 's' (logprob: -2.1181) [Prédiction principale]
  2. 'count' (logprob: -2.4931)
* 3. 'print' (logprob: -2.6181)
  4. 'n' (logprob: -2.8681)
  5. 'if' (logprob: -2.8681)
  6. 'v' (logprob: -3.1181)
  7. 'result' (logprob: -3.1181)
  8. 'for' (logprob: -3.2431)
  9. 'unique' (logprob: -3.7431)
  10. '#' (logprob: -3.9931)

Le token attendu est à la position 3 dans les prédictions.

--------------------------------------------------------------------------------

Position 10: '(s' (ID: 1858)
Prédiction principale: '(s' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '(s' (logprob: -0.1737) [Prédiction principale]
  2. '("' (logprob: -3.0487)
  3. '('' (logprob: -3.4237)
  4. '(f' (logprob: -4.0487)
  5. '(len' (logprob: -4.1737)
  6. '(' (logprob: -5.0487)
  7. ' (' (logprob: -5.7987)
  8. '(re' (logprob: -5.9237)
  9. '(is' (logprob: -6.0487)
  10. '(count' (logprob: -6.0487)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 11: ')' (ID: 8)
Prédiction principale: ')' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. ')' (logprob: -0.5524) [Prédiction principale]
  2. ')\n' (logprob: -1.0524)
  3. ')\n\n' (logprob: -3.6774)
  4. '.count' (logprob: -3.8024)
  5. '[::-' (logprob: -4.9274)
  6. '[' (logprob: -5.5524)
  7. '.replace' (logprob: -5.5524)
  8. ',' (logprob: -6.1774)
  9. '[:' (logprob: -6.4274)
  10. '.lower' (logprob: -6.9274)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------


RÉSUMÉ:
--------------------------------------------------------------------------------
Total des tokens analysés: 9
Tokens correctement prédits (1ère position, stricte): 5
Tokens correctement prédits (1ère position, avec adaptation): 5
Tokens correctement prédits (top 10): 9
Précision stricte (1ère position): 55.56%
Précision adaptée (1ère position): 55.56%
Précision (top 10): 100.00%
================================================================================

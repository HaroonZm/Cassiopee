================================================================================
ANALYSE DES PRÉDICTIONS DE TOKENS
================================================================================

SCRIPT ORIGINAL:
--------------------------------------------------------------------------------
print(raw_input().upper())
--------------------------------------------------------------------------------

INFORMATION SUR LA TOKENISATION:
--------------------------------------------------------------------------------
Tokenisation utilisée: tiktoken pour le modèle gpt-4o-mini
Il s'agit de la tokenisation officielle utilisée par les modèles OpenAI.
--------------------------------------------------------------------------------

TOKENS IDENTIFIÉS:
--------------------------------------------------------------------------------
Token 0: 'print' (ID: 1598)
Token 1: '(raw' (ID: 46707)
Token 2: '_input' (ID: 12507)
Token 3: '().' (ID: 1454)
Token 4: 'upper' (ID: 26119)
Token 5: '())' (ID: 3516)
--------------------------------------------------------------------------------

INFORMATIONS SUR LA MATRICE 2D DE LOG PROBABILITÉS:
--------------------------------------------------------------------------------
Dimensions de la matrice: 1 lignes x 6 tokens max
Nombre de tokens par ligne: [6]
Convention de valeurs:
  - Log probabilité normale: Valeur réelle (typiquement entre -1 et -20)
  - Anomalie (token hors top-10): -50
  - Padding (positions vides): 100

Matrice 2D (format texte simplifiée):
[-10.00, -10.00, -3.63, -3.31, -6.19, -0.71, ]

Note: La matrice a été sauvegardée au format numpy dans 'matrice_logprob.npy'
--------------------------------------------------------------------------------

ANALYSE TOKEN PAR TOKEN:
--------------------------------------------------------------------------------
Position 0: 'print' (ID: 1598) (token d'amorce)
--------------------------------------------------------------------------------

Position 1: '(raw' (ID: 46707) (token d'amorce)
--------------------------------------------------------------------------------

Position 2: '_input' (ID: 12507)
Prédiction principale: '_data' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '_data' (logprob: -1.1278) [Prédiction principale]
  2. '_text' (logprob: -3.3778)
  3. ')\n' (logprob: -3.5028)
  4. 'Data' (logprob: -3.5028)
* 5. '_input' (logprob: -3.6278)
  6. '_string' (logprob: -3.7528)
  7. ')\n\n' (logprob: -3.8778)
  8. '_df' (logprob: -3.8778)
  9. ')' (logprob: -4.0028)
  10. '_output' (logprob: -4.1278)

Le token attendu est à la position 5 dans les prédictions.

--------------------------------------------------------------------------------

Position 3: '().' (ID: 1454)
Prédiction principale: '("' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '("' (logprob: -1.1880) [Prédiction principale]
  2. '())\n' (logprob: -2.0630)
  3. '('' (logprob: -2.1880)
  4. '())' (logprob: -2.5630)
  5. ')\n' (logprob: -2.8130)
  6. ')' (logprob: -3.3130)
* 7. '().' (logprob: -3.3130)
  8. '())\n\n' (logprob: -3.4380)
  9. ')\n\n' (logprob: -4.0630)
  10. '(' (logprob: -4.6880)

Le token attendu est à la position 7 dans les prédictions.

--------------------------------------------------------------------------------

Position 4: 'upper' (ID: 26119)
Prédiction principale: 'strip' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. 'strip' (logprob: -0.1870) [Prédiction principale]
  2. 'split' (logprob: -2.0620)
  3. 'rstrip' (logprob: -4.3120)
  4. 'replace' (logprob: -4.5620)
  5. 'lower' (logprob: -5.1870)
  6. 'encode' (logprob: -5.5620)
  7. 'decode' (logprob: -5.6870)
* 8. 'upper' (logprob: -6.1870)
  9. 'count' (logprob: -7.8120)
  10. 'l' (logprob: -8.1870)

Le token attendu est à la position 8 dans les prédictions.

--------------------------------------------------------------------------------

Position 5: '())' (ID: 3516)
Prédiction principale: '())' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '())' (logprob: -0.7119) [Prédiction principale]
  2. '())\n' (logprob: -1.2119)
  3. '())\n\n' (logprob: -2.7119)
  4. '().' (logprob: -3.0869)
  5. '())\r\n' (logprob: -3.2119)
  6. '()' (logprob: -3.4619)
  7. '(),' (logprob: -4.4619)
  8. '()[' (logprob: -4.8369)
  9. '())\n\n\n' (logprob: -6.0869)
  10. '()).' (logprob: -7.3369)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------


RÉSUMÉ:
--------------------------------------------------------------------------------
Total des tokens analysés: 4
Tokens correctement prédits (1ère position, stricte): 1
Tokens correctement prédits (1ère position, avec adaptation): 1
Tokens correctement prédits (top 10): 4
Précision stricte (1ère position): 25.00%
Précision adaptée (1ère position): 25.00%
Précision (top 10): 100.00%
================================================================================

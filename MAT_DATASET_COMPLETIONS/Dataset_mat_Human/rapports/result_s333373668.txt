================================================================================
ANALYSE DES PRÉDICTIONS DE TOKENS
================================================================================

SCRIPT ORIGINAL:
--------------------------------------------------------------------------------
x=str(input())
print(x.upper())
--------------------------------------------------------------------------------

INFORMATION SUR LA TOKENISATION:
--------------------------------------------------------------------------------
Tokenisation utilisée: tiktoken pour le modèle gpt-4o-mini
Il s'agit de la tokenisation officielle utilisée par les modèles OpenAI.
--------------------------------------------------------------------------------

TOKENS IDENTIFIÉS:
--------------------------------------------------------------------------------
Token 0: 'x' (ID: 87)
Token 1: '=str' (ID: 36106)
Token 2: '(input' (ID: 10054)
Token 3: '())\n' (ID: 4574)
Token 4: 'print' (ID: 1598)
Token 5: '(x' (ID: 4061)
Token 6: '.upper' (ID: 75082)
Token 7: '())' (ID: 3516)
--------------------------------------------------------------------------------

INFORMATIONS SUR LA MATRICE 2D DE LOG PROBABILITÉS:
--------------------------------------------------------------------------------
Dimensions de la matrice: 2 lignes x 4 tokens max
Nombre de tokens par ligne: [4, 4]
Convention de valeurs:
  - Log probabilité normale: Valeur réelle (typiquement entre -1 et -20)
  - Anomalie (token hors top-10): -50
  - Padding (positions vides): 100

Matrice 2D (format texte simplifiée):
[-10.00, -10.00, -2.71, -1.93, ]
[-2.35, -0.73, -3.60, -0.46, ]

Note: La matrice a été sauvegardée au format numpy dans 'matrice_logprob.npy'
--------------------------------------------------------------------------------

ANALYSE TOKEN PAR TOKEN:
--------------------------------------------------------------------------------
Position 0: 'x' (ID: 87) (token d'amorce)
--------------------------------------------------------------------------------

Position 1: '=str' (ID: 36106) (token d'amorce)
--------------------------------------------------------------------------------

Position 2: '(input' (ID: 10054)
Prédiction principale: '(x' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '(x' (logprob: -2.7066) [Prédiction principale]
* 2. '(input' (logprob: -2.7066)
  3. '(i' (logprob: -2.9566)
  4. '(' (logprob: -3.0816)
  5. '2' (logprob: -3.3316)
  6. '(s' (logprob: -3.5816)
  7. '.replace' (logprob: -3.8316)
  8. '(int' (logprob: -3.9566)
  9. '(a' (logprob: -3.9566)
  10. '(n' (logprob: -4.0816)

Le token attendu est à la position 2 dans les prédictions.

--------------------------------------------------------------------------------

Position 3: '())\n' (ID: 4574)
Prédiction principale: '("' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '("' (logprob: -0.6816) [Prédiction principale]
  2. '('' (logprob: -1.4316)
* 3. '())\n' (logprob: -1.9316)
  4. '())' (logprob: -3.4316)
  5. '())\r\n' (logprob: -3.5566)
  6. '())\n\n' (logprob: -4.6816)
  7. '().' (logprob: -5.0566)
  8. '(f' (logprob: -5.0566)
  9. '("\\' (logprob: -5.3066)
  10. '()).' (logprob: -5.9316)

Le token attendu est à la position 3 dans les prédictions.

--------------------------------------------------------------------------------

Position 4: 'print' (ID: 1598)
Prédiction principale: 'y' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. 'y' (logprob: -1.5982) [Prédiction principale]
  2. 'if' (logprob: -1.7232)
* 3. 'print' (logprob: -2.3482)
  4. 'x' (logprob: -2.7232)
  5. 'n' (logprob: -3.2232)
  6. 'a' (logprob: -3.4732)
  7. 's' (logprob: -3.4732)
  8. 'for' (logprob: -3.5982)
  9. 'l' (logprob: -3.8482)
  10. '#' (logprob: -3.9732)

Le token attendu est à la position 3 dans les prédictions.

--------------------------------------------------------------------------------

Position 5: '(x' (ID: 4061)
Prédiction principale: '(x' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '(x' (logprob: -0.7271) [Prédiction principale]
  2. '("' (logprob: -2.2271)
  3. '('' (logprob: -3.1021)
  4. ' (' (logprob: -3.2271)
  5. '(f' (logprob: -3.3521)
  6. '(len' (logprob: -3.3521)
  7. '(str' (logprob: -3.4771)
  8. '(' (logprob: -3.9771)
  9. '(s' (logprob: -4.1021)
  10. '(int' (logprob: -4.2271)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 6: '.upper' (ID: 75082)
Prédiction principale: ')\n' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. ')\n' (logprob: -1.2283) [Prédiction principale]
  2. '[::-' (logprob: -1.7283)
  3. ')' (logprob: -1.8533)
  4. '[' (logprob: -2.4783)
  5. ')\n\n' (logprob: -3.2283)
  6. '.count' (logprob: -3.3533)
  7. '[-' (logprob: -3.3533)
* 8. '.upper' (logprob: -3.6033)
  9. '.replace' (logprob: -3.7283)
  10. '.is' (logprob: -4.2283)

Le token attendu est à la position 8 dans les prédictions.

--------------------------------------------------------------------------------

Position 7: '())' (ID: 3516)
Prédiction principale: '())' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '())' (logprob: -0.4586) [Prédiction principale]
  2. '())\n' (logprob: -1.2086)
  3. '())\n\n' (logprob: -2.9586)
  4. '().' (logprob: -5.3336)
  5. '(),' (logprob: -5.3336)
  6. '()' (logprob: -5.8336)
  7. '()[' (logprob: -6.4586)
  8. '())\n\n\n' (logprob: -6.5836)
  9. '()+' (logprob: -7.9586)
  10. ')' (logprob: -8.4586)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------


RÉSUMÉ:
--------------------------------------------------------------------------------
Total des tokens analysés: 6
Tokens correctement prédits (1ère position, stricte): 2
Tokens correctement prédits (1ère position, avec adaptation): 2
Tokens correctement prédits (top 10): 6
Précision stricte (1ère position): 33.33%
Précision adaptée (1ère position): 33.33%
Précision (top 10): 100.00%
================================================================================

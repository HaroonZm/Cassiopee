================================================================================
ANALYSE DES PRÉDICTIONS DE TOKENS
================================================================================

SCRIPT ORIGINAL:
--------------------------------------------------------------------------------
s = input()
print(s.upper())
--------------------------------------------------------------------------------

INFORMATION SUR LA TOKENISATION:
--------------------------------------------------------------------------------
Tokenisation utilisée: tiktoken pour le modèle gpt-4o-mini
Il s'agit de la tokenisation officielle utilisée par les modèles OpenAI.
--------------------------------------------------------------------------------

TOKENS IDENTIFIÉS:
--------------------------------------------------------------------------------
Token 0: 's' (ID: 82)
Token 1: ' =' (ID: 314)
Token 2: ' input' (ID: 3422)
Token 3: '()\n' (ID: 1234)
Token 4: 'print' (ID: 1598)
Token 5: '(s' (ID: 1858)
Token 6: '.upper' (ID: 75082)
Token 7: '())' (ID: 3516)
--------------------------------------------------------------------------------

INFORMATIONS SUR LA MATRICE 2D DE LOG PROBABILITÉS:
--------------------------------------------------------------------------------
Dimensions de la matrice: 2 lignes x 4 tokens max
Nombre de tokens par ligne: [4, 4]
Convention de valeurs:
  - Log probabilité normale: Valeur réelle (typiquement entre -1 et -20)
  - Anomalie (token hors top-10): -50
  - Padding (positions vides): 100

Matrice 2D (format texte simplifiée):
[-10.00, -10.00, ANOM, -3.53, ]
[-2.31, -1.68, ANOM, -0.59, ]

Note: La matrice a été sauvegardée au format numpy dans 'matrice_logprob.npy'
--------------------------------------------------------------------------------

ANALYSE TOKEN PAR TOKEN:
--------------------------------------------------------------------------------
Position 0: 's' (ID: 82) (token d'amorce)
--------------------------------------------------------------------------------

Position 1: ' =' (ID: 314) (token d'amorce)
--------------------------------------------------------------------------------

Position 2: ' input' (ID: 3422)
Prédiction principale: ' ' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. ' ' (logprob: -1.7689) [Prédiction principale]
  2. ' [' (logprob: -2.8939)
  3. ' []\n' (logprob: -3.2689)
  4. ' new' (logprob: -3.3939)
  5. ' (' (logprob: -3.5189)
  6. ' np' (logprob: -3.7689)
  7. ' "' (logprob: -3.8939)
  8. ' self' (logprob: -4.3939)
  9. ' []\n\n' (logprob: -4.3939)
  10. ' s' (logprob: -4.5189)

Le token attendu n'est pas dans le top 10 des prédictions.

--------------------------------------------------------------------------------

Position 3: '()\n' (ID: 1234)
Prédiction principale: '("' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. '("' (logprob: -0.6554) [Prédiction principale]
  2. '().' (logprob: -1.6554)
  3. '('' (logprob: -3.2804)
* 4. '()\n' (logprob: -3.5304)
  5. '.split' (logprob: -3.5304)
  6. '_string' (logprob: -3.7804)
  7. 'String' (logprob: -4.6554)
  8. '_str' (logprob: -4.6554)
  9. '_list' (logprob: -4.7804)
  10. '(f' (logprob: -4.9054)

Le token attendu est à la position 4 dans les prédictions.

--------------------------------------------------------------------------------

Position 4: 'print' (ID: 1598)
Prédiction principale: 'print' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. 'print' (logprob: -2.3091) [Prédiction principale]
  2. 'n' (logprob: -2.6841)
  3. 's' (logprob: -2.6841)
  4. '#' (logprob: -2.8091)
  5. 'if' (logprob: -3.5591)
  6. 'result' (logprob: -3.5591)
  7. 'for' (logprob: -3.6841)
  8. 't' (logprob: -3.9341)
  9. 'count' (logprob: -3.9341)
  10. 'a' (logprob: -4.0591)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 5: '(s' (ID: 1858)
Prédiction principale: '(s' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '(s' (logprob: -1.6773) [Prédiction principale]
  2. '(count' (logprob: -2.5523)
  3. '("' (logprob: -2.6773)
  4. '(' (logprob: -2.9273)
  5. '(is' (logprob: -3.0523)
  6. '(f' (logprob: -3.3023)
  7. '(find' (logprob: -3.5523)
  8. '('' (logprob: -3.6773)
  9. '(c' (logprob: -3.8023)
  10. '(get' (logprob: -3.8023)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------

Position 6: '.upper' (ID: 75082)
Prédiction principale: ')\n' (✗ INCORRECT)

Top 10 tokens les plus probables:
  1. ')\n' (logprob: -1.6671) [Prédiction principale]
  2. '.count' (logprob: -1.7921)
  3. '[' (logprob: -2.1671)
  4. '[::-' (logprob: -2.2921)
  5. ')' (logprob: -2.5421)
  6. '.replace' (logprob: -2.9171)
  7. ')\n\n' (logprob: -3.0421)
  8. '[-' (logprob: -3.5421)
  9. '[:' (logprob: -3.9171)
  10. ',' (logprob: -4.0421)

Le token attendu n'est pas dans le top 10 des prédictions.

--------------------------------------------------------------------------------

Position 7: '())' (ID: 3516)
Prédiction principale: '())' (✓ CORRECT)

Top 10 tokens les plus probables:
* 1. '())' (logprob: -0.5868) [Prédiction principale]
  2. '())\n' (logprob: -0.9618)
  3. '())\n\n' (logprob: -3.4618)
  4. '()' (logprob: -4.4618)
  5. '(),' (logprob: -4.8368)
  6. '().' (logprob: -5.0868)
  7. '()[' (logprob: -5.8368)
  8. '())\n\n\n' (logprob: -7.3368)
  9. '(' (logprob: -8.7118)
  10. '()+' (logprob: -9.0868)

Le token attendu est à la position 1 dans les prédictions.

--------------------------------------------------------------------------------


RÉSUMÉ:
--------------------------------------------------------------------------------
Total des tokens analysés: 6
Tokens correctement prédits (1ère position, stricte): 3
Tokens correctement prédits (1ère position, avec adaptation): 3
Tokens correctement prédits (top 10): 4
Précision stricte (1ère position): 50.00%
Précision adaptée (1ère position): 50.00%
Précision (top 10): 66.67%
================================================================================
